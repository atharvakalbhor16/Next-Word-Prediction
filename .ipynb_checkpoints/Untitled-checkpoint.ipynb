{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92a6fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c4f5e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If only I had more self-control. I don’t have such an iron mind. I want to enjoy life, too — not just suffer. These are comments I might get when people learn about my lifestyle. I’m one of those annoying people who eats lots of fruits and vegetables, exercises five times a week, saves a portion of their salary, and writes or reads every morning before work — I have good self-control. What’s more, retaining this lifestyle doesn’t feel particularly difficult to me; I don’t grit my teeth to avoid '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"Self.txt\", \"r\", encoding = \"utf8\")\n",
    "\n",
    "# store file in list\n",
    "lines = []\n",
    "for i in file:\n",
    "    lines.append(i)\n",
    " \n",
    "# Convert list to string\n",
    "data = \"\"\n",
    "for i in lines:\n",
    "  data = ' '. join(lines) \n",
    " \n",
    "#replace unnecessary stuff with space\n",
    "data = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '').replace('“','').replace('”','')  #new line, carriage return, unicode character --> replace by space\n",
    " \n",
    "#remove unnecessary spaces \n",
    "data = data.split()\n",
    "data = ' '.join(data)\n",
    "data[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d097e848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11958"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eca774e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677\n",
      "The Length of sequences are:  1974\n",
      "Data:  [[ 32 110  15]\n",
      " [110  15 274]\n",
      " [ 15 274  16]\n",
      " [274  16   2]\n",
      " [ 16   2   4]\n",
      " [  2   4  15]\n",
      " [  4  15  79]\n",
      " [ 15  79  13]\n",
      " [ 79  13 156]\n",
      " [ 13 156  56]]\n",
      "Response:  [274  16   2   4  15  79  13 156  56 275]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    " \n",
    "# saving the tokenizer for predict function\n",
    "pickle.dump(tokenizer, open('token.pkl', 'wb'))\n",
    " \n",
    "sequence_data = tokenizer.texts_to_sequences([data])[0]\n",
    "sequence_data[:15]\n",
    "len(sequence_data)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)\n",
    "sequences = []\n",
    " \n",
    "for i in range(3, len(sequence_data)):\n",
    "    words = sequence_data[i-3:i+1]\n",
    "    sequences.append(words)\n",
    "     \n",
    "print(\"The Length of sequences are: \", len(sequences))\n",
    "sequences = np.array(sequences)\n",
    "sequences[:10]\n",
    "X = []\n",
    "y = []\n",
    " \n",
    "for i in sequences:\n",
    "    X.append(i[0:3])\n",
    "    y.append(i[3])\n",
    "     \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(\"Data: \", X[:10])\n",
    "print(\"Response: \", y[:10])\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4441eb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=3))\n",
    "model.add(LSTM(1000, return_sequences=True))\n",
    "model.add(LSTM(1000))\n",
    "model.add(Dense(1000, activation=\"relu\"))\n",
    "model.add(Dense(vocab_size, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25a7e00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 3, 10)             6770      \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 3, 1000)           4044000   \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 1000)              8004000   \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 677)               677677    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13733447 (52.39 MB)\n",
      "Trainable params: 13733447 (52.39 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4540ceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    " #from tensorflow import keras\n",
    "#from keras.utils import plot_model\n",
    "#keras.utils.plot_model(model, to_file='plot.png', show_layer_names=True)\n",
    "\n",
    "# Gives ERROR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "17ad0b6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "WARNING:tensorflow:From C:\\Users\\Vedant\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "31/31 [==============================] - ETA: 0s - loss: 4.9113 - accuracy: 0.0800\n",
      "Epoch 1: loss improved from inf to 4.91127, saving model to next_words.h5\n",
      "31/31 [==============================] - 19s 413ms/step - loss: 4.9113 - accuracy: 0.0800\n",
      "Epoch 2/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 4.6459 - accuracy: 0.0957\n",
      "Epoch 2: loss improved from 4.91127 to 4.64589, saving model to next_words.h5\n",
      "31/31 [==============================] - 14s 449ms/step - loss: 4.6459 - accuracy: 0.0957\n",
      "Epoch 3/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 4.4621 - accuracy: 0.1033\n",
      "Epoch 3: loss improved from 4.64589 to 4.46214, saving model to next_words.h5\n",
      "31/31 [==============================] - 13s 415ms/step - loss: 4.4621 - accuracy: 0.1033\n",
      "Epoch 4/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 4.2246 - accuracy: 0.1196\n",
      "Epoch 4: loss improved from 4.46214 to 4.22465, saving model to next_words.h5\n",
      "31/31 [==============================] - 75s 2s/step - loss: 4.2246 - accuracy: 0.1196\n",
      "Epoch 5/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 4.0373 - accuracy: 0.1282\n",
      "Epoch 5: loss improved from 4.22465 to 4.03733, saving model to next_words.h5\n",
      "31/31 [==============================] - 13s 432ms/step - loss: 4.0373 - accuracy: 0.1282\n",
      "Epoch 6/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 3.7489 - accuracy: 0.1479\n",
      "Epoch 6: loss improved from 4.03733 to 3.74892, saving model to next_words.h5\n",
      "31/31 [==============================] - 15s 471ms/step - loss: 3.7489 - accuracy: 0.1479\n",
      "Epoch 7/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 3.4772 - accuracy: 0.1611\n",
      "Epoch 7: loss improved from 3.74892 to 3.47718, saving model to next_words.h5\n",
      "31/31 [==============================] - 15s 475ms/step - loss: 3.4772 - accuracy: 0.1611\n",
      "Epoch 8/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 3.2247 - accuracy: 0.2107\n",
      "Epoch 8: loss improved from 3.47718 to 3.22466, saving model to next_words.h5\n",
      "31/31 [==============================] - 14s 457ms/step - loss: 3.2247 - accuracy: 0.2107\n",
      "Epoch 9/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 3.0274 - accuracy: 0.2259\n",
      "Epoch 9: loss improved from 3.22466 to 3.02736, saving model to next_words.h5\n",
      "31/31 [==============================] - 14s 440ms/step - loss: 3.0274 - accuracy: 0.2259\n",
      "Epoch 10/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 2.8385 - accuracy: 0.2492\n",
      "Epoch 10: loss improved from 3.02736 to 2.83855, saving model to next_words.h5\n",
      "31/31 [==============================] - 11s 354ms/step - loss: 2.8385 - accuracy: 0.2492\n",
      "Epoch 11/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 2.6341 - accuracy: 0.2953\n",
      "Epoch 11: loss improved from 2.83855 to 2.63407, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 187ms/step - loss: 2.6341 - accuracy: 0.2953\n",
      "Epoch 12/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 2.4758 - accuracy: 0.3227\n",
      "Epoch 12: loss improved from 2.63407 to 2.47578, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 184ms/step - loss: 2.4758 - accuracy: 0.3227\n",
      "Epoch 13/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 2.2047 - accuracy: 0.4032\n",
      "Epoch 13: loss improved from 2.47578 to 2.20474, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 185ms/step - loss: 2.2047 - accuracy: 0.4032\n",
      "Epoch 14/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 2.0528 - accuracy: 0.4189\n",
      "Epoch 14: loss improved from 2.20474 to 2.05280, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 184ms/step - loss: 2.0528 - accuracy: 0.4189\n",
      "Epoch 15/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.9540 - accuracy: 0.4417\n",
      "Epoch 15: loss improved from 2.05280 to 1.95403, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 182ms/step - loss: 1.9540 - accuracy: 0.4417\n",
      "Epoch 16/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.8239 - accuracy: 0.4686\n",
      "Epoch 16: loss improved from 1.95403 to 1.82391, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 181ms/step - loss: 1.8239 - accuracy: 0.4686\n",
      "Epoch 17/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.6518 - accuracy: 0.5137\n",
      "Epoch 17: loss improved from 1.82391 to 1.65181, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 182ms/step - loss: 1.6518 - accuracy: 0.5137\n",
      "Epoch 18/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.4589 - accuracy: 0.5724\n",
      "Epoch 18: loss improved from 1.65181 to 1.45892, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 182ms/step - loss: 1.4589 - accuracy: 0.5724\n",
      "Epoch 19/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.3768 - accuracy: 0.5856\n",
      "Epoch 19: loss improved from 1.45892 to 1.37677, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 180ms/step - loss: 1.3768 - accuracy: 0.5856\n",
      "Epoch 20/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.3377 - accuracy: 0.5957\n",
      "Epoch 20: loss improved from 1.37677 to 1.33772, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 182ms/step - loss: 1.3377 - accuracy: 0.5957\n",
      "Epoch 21/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.1928 - accuracy: 0.6398\n",
      "Epoch 21: loss improved from 1.33772 to 1.19277, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 181ms/step - loss: 1.1928 - accuracy: 0.6398\n",
      "Epoch 22/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.1250 - accuracy: 0.6499\n",
      "Epoch 22: loss improved from 1.19277 to 1.12497, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 181ms/step - loss: 1.1250 - accuracy: 0.6499\n",
      "Epoch 23/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.1741 - accuracy: 0.6474\n",
      "Epoch 23: loss did not improve from 1.12497\n",
      "31/31 [==============================] - 5s 176ms/step - loss: 1.1741 - accuracy: 0.6474\n",
      "Epoch 24/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.0402 - accuracy: 0.6722\n",
      "Epoch 24: loss improved from 1.12497 to 1.04018, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 180ms/step - loss: 1.0402 - accuracy: 0.6722\n",
      "Epoch 25/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.8808 - accuracy: 0.7259\n",
      "Epoch 25: loss improved from 1.04018 to 0.88075, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 181ms/step - loss: 0.8808 - accuracy: 0.7259\n",
      "Epoch 26/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.7880 - accuracy: 0.7604\n",
      "Epoch 26: loss improved from 0.88075 to 0.78801, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 181ms/step - loss: 0.7880 - accuracy: 0.7604\n",
      "Epoch 27/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.7788 - accuracy: 0.7573\n",
      "Epoch 27: loss improved from 0.78801 to 0.77883, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 179ms/step - loss: 0.7788 - accuracy: 0.7573\n",
      "Epoch 28/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.7044 - accuracy: 0.7852\n",
      "Epoch 28: loss improved from 0.77883 to 0.70445, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 180ms/step - loss: 0.7044 - accuracy: 0.7852\n",
      "Epoch 29/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.5738 - accuracy: 0.8217\n",
      "Epoch 29: loss improved from 0.70445 to 0.57385, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 180ms/step - loss: 0.5738 - accuracy: 0.8217\n",
      "Epoch 30/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.5322 - accuracy: 0.8384\n",
      "Epoch 30: loss improved from 0.57385 to 0.53221, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 180ms/step - loss: 0.5322 - accuracy: 0.8384\n",
      "Epoch 31/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.5271 - accuracy: 0.8404\n",
      "Epoch 31: loss improved from 0.53221 to 0.52713, saving model to next_words.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 6s 182ms/step - loss: 0.5271 - accuracy: 0.8404\n",
      "Epoch 32/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4913 - accuracy: 0.8516\n",
      "Epoch 32: loss improved from 0.52713 to 0.49129, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 182ms/step - loss: 0.4913 - accuracy: 0.8516\n",
      "Epoch 33/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4337 - accuracy: 0.8698\n",
      "Epoch 33: loss improved from 0.49129 to 0.43369, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 180ms/step - loss: 0.4337 - accuracy: 0.8698\n",
      "Epoch 34/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4483 - accuracy: 0.8632\n",
      "Epoch 34: loss did not improve from 0.43369\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 0.4483 - accuracy: 0.8632\n",
      "Epoch 35/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.5292 - accuracy: 0.8369\n",
      "Epoch 35: loss did not improve from 0.43369\n",
      "31/31 [==============================] - 5s 175ms/step - loss: 0.5292 - accuracy: 0.8369\n",
      "Epoch 36/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4914 - accuracy: 0.8480\n",
      "Epoch 36: loss did not improve from 0.43369\n",
      "31/31 [==============================] - 6s 183ms/step - loss: 0.4914 - accuracy: 0.8480\n",
      "Epoch 37/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4505 - accuracy: 0.8647\n",
      "Epoch 37: loss did not improve from 0.43369\n",
      "31/31 [==============================] - 6s 180ms/step - loss: 0.4505 - accuracy: 0.8647\n",
      "Epoch 38/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4357 - accuracy: 0.8561\n",
      "Epoch 38: loss did not improve from 0.43369\n",
      "31/31 [==============================] - 6s 177ms/step - loss: 0.4357 - accuracy: 0.8561\n",
      "Epoch 39/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4368 - accuracy: 0.8647\n",
      "Epoch 39: loss did not improve from 0.43369\n",
      "31/31 [==============================] - 6s 178ms/step - loss: 0.4368 - accuracy: 0.8647\n",
      "Epoch 40/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3936 - accuracy: 0.8865\n",
      "Epoch 40: loss improved from 0.43369 to 0.39356, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 185ms/step - loss: 0.3936 - accuracy: 0.8865\n",
      "Epoch 41/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3136 - accuracy: 0.9022\n",
      "Epoch 41: loss improved from 0.39356 to 0.31357, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 181ms/step - loss: 0.3136 - accuracy: 0.9022\n",
      "Epoch 42/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.2976 - accuracy: 0.9093\n",
      "Epoch 42: loss improved from 0.31357 to 0.29757, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 180ms/step - loss: 0.2976 - accuracy: 0.9093\n",
      "Epoch 43/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.2786 - accuracy: 0.9129\n",
      "Epoch 43: loss improved from 0.29757 to 0.27856, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 182ms/step - loss: 0.2786 - accuracy: 0.9129\n",
      "Epoch 44/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.2679 - accuracy: 0.9169\n",
      "Epoch 44: loss improved from 0.27856 to 0.26791, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 183ms/step - loss: 0.2679 - accuracy: 0.9169\n",
      "Epoch 45/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.2764 - accuracy: 0.9184\n",
      "Epoch 45: loss did not improve from 0.26791\n",
      "31/31 [==============================] - 5s 176ms/step - loss: 0.2764 - accuracy: 0.9184\n",
      "Epoch 46/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.2458 - accuracy: 0.9215\n",
      "Epoch 46: loss improved from 0.26791 to 0.24578, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 182ms/step - loss: 0.2458 - accuracy: 0.9215\n",
      "Epoch 47/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.2216 - accuracy: 0.9255\n",
      "Epoch 47: loss improved from 0.24578 to 0.22158, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 182ms/step - loss: 0.2216 - accuracy: 0.9255\n",
      "Epoch 48/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.2252 - accuracy: 0.9276\n",
      "Epoch 48: loss did not improve from 0.22158\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 0.2252 - accuracy: 0.9276\n",
      "Epoch 49/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.2414 - accuracy: 0.9200\n",
      "Epoch 49: loss did not improve from 0.22158\n",
      "31/31 [==============================] - 5s 175ms/step - loss: 0.2414 - accuracy: 0.9200\n",
      "Epoch 50/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.2204 - accuracy: 0.9235\n",
      "Epoch 50: loss improved from 0.22158 to 0.22043, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 180ms/step - loss: 0.2204 - accuracy: 0.9235\n",
      "Epoch 51/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.2214 - accuracy: 0.9291\n",
      "Epoch 51: loss did not improve from 0.22043\n",
      "31/31 [==============================] - 5s 174ms/step - loss: 0.2214 - accuracy: 0.9291\n",
      "Epoch 52/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.2308 - accuracy: 0.9225\n",
      "Epoch 52: loss did not improve from 0.22043\n",
      "31/31 [==============================] - 5s 173ms/step - loss: 0.2308 - accuracy: 0.9225\n",
      "Epoch 53/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.2649 - accuracy: 0.9169\n",
      "Epoch 53: loss did not improve from 0.22043\n",
      "31/31 [==============================] - 5s 172ms/step - loss: 0.2649 - accuracy: 0.9169\n",
      "Epoch 54/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3657 - accuracy: 0.8850\n",
      "Epoch 54: loss did not improve from 0.22043\n",
      "31/31 [==============================] - 5s 173ms/step - loss: 0.3657 - accuracy: 0.8850\n",
      "Epoch 55/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4893 - accuracy: 0.8425\n",
      "Epoch 55: loss did not improve from 0.22043\n",
      "31/31 [==============================] - 5s 172ms/step - loss: 0.4893 - accuracy: 0.8425\n",
      "Epoch 56/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.5593 - accuracy: 0.8278\n",
      "Epoch 56: loss did not improve from 0.22043\n",
      "31/31 [==============================] - 5s 172ms/step - loss: 0.5593 - accuracy: 0.8278\n",
      "Epoch 57/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.5605 - accuracy: 0.8267\n",
      "Epoch 57: loss did not improve from 0.22043\n",
      "31/31 [==============================] - 5s 177ms/step - loss: 0.5605 - accuracy: 0.8267\n",
      "Epoch 58/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.4789 - accuracy: 0.8419\n",
      "Epoch 58: loss did not improve from 0.22043\n",
      "31/31 [==============================] - 5s 172ms/step - loss: 0.4789 - accuracy: 0.8419\n",
      "Epoch 59/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3647 - accuracy: 0.8774\n",
      "Epoch 59: loss did not improve from 0.22043\n",
      "31/31 [==============================] - 5s 172ms/step - loss: 0.3647 - accuracy: 0.8774\n",
      "Epoch 60/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.2816 - accuracy: 0.9129\n",
      "Epoch 60: loss did not improve from 0.22043\n",
      "31/31 [==============================] - 5s 172ms/step - loss: 0.2816 - accuracy: 0.9129\n",
      "Epoch 61/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.2158 - accuracy: 0.9250\n",
      "Epoch 61: loss improved from 0.22043 to 0.21577, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 178ms/step - loss: 0.2158 - accuracy: 0.9250\n",
      "Epoch 62/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.2193 - accuracy: 0.9235\n",
      "Epoch 62: loss did not improve from 0.21577\n",
      "31/31 [==============================] - 5s 172ms/step - loss: 0.2193 - accuracy: 0.9235\n",
      "Epoch 63/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.1818 - accuracy: 0.9367\n",
      "Epoch 63: loss improved from 0.21577 to 0.18176, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 181ms/step - loss: 0.1818 - accuracy: 0.9367\n",
      "Epoch 64/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.1621 - accuracy: 0.9417\n",
      "Epoch 64: loss improved from 0.18176 to 0.16211, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 179ms/step - loss: 0.1621 - accuracy: 0.9417\n",
      "Epoch 65/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.1635 - accuracy: 0.9412\n",
      "Epoch 65: loss did not improve from 0.16211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 5s 172ms/step - loss: 0.1635 - accuracy: 0.9412\n",
      "Epoch 66/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.1499 - accuracy: 0.9392\n",
      "Epoch 66: loss improved from 0.16211 to 0.14985, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 180ms/step - loss: 0.1499 - accuracy: 0.9392\n",
      "Epoch 67/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.1431 - accuracy: 0.9397\n",
      "Epoch 67: loss improved from 0.14985 to 0.14308, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 179ms/step - loss: 0.1431 - accuracy: 0.9397\n",
      "Epoch 68/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.1424 - accuracy: 0.9387\n",
      "Epoch 68: loss improved from 0.14308 to 0.14239, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 179ms/step - loss: 0.1424 - accuracy: 0.9387\n",
      "Epoch 69/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.1378 - accuracy: 0.9412\n",
      "Epoch 69: loss improved from 0.14239 to 0.13777, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 179ms/step - loss: 0.1378 - accuracy: 0.9412\n",
      "Epoch 70/70\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.1323 - accuracy: 0.9422\n",
      "Epoch 70: loss improved from 0.13777 to 0.13225, saving model to next_words.h5\n",
      "31/31 [==============================] - 6s 179ms/step - loss: 0.1323 - accuracy: 0.9422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x201bcb9d410>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "checkpoint = ModelCheckpoint(\"next_words.h5\", monitor='loss', verbose=1, save_best_only=True)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=70, batch_size=64, callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6966c67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d3d295",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the model and tokenizer\n",
    "model = load_model('next_words.h5')\n",
    "tokenizer = pickle.load(open('token.pkl', 'rb'))\n",
    " \n",
    "def Predict_Next_Words(model, tokenizer, text):\n",
    " \n",
    "  sequence = tokenizer.texts_to_sequences([text])\n",
    "  sequence = np.array(sequence)\n",
    "  preds = np.argmax(model.predict(sequence))\n",
    "  predicted_word = \"\"\n",
    "   \n",
    "  for key, value in tokenizer.word_index.items():\n",
    "      if value == preds:\n",
    "          predicted_word = key\n",
    "          break\n",
    "   \n",
    "  print(predicted_word)\n",
    "  return predicted_word\n",
    "while(True):\n",
    "  text = input(\"Enter your line: \")\n",
    "   \n",
    "  if text == \"0\":\n",
    "      print(\"Execution completed.....\")\n",
    "      break\n",
    "   \n",
    "  else:\n",
    "      try:\n",
    "          text = text.split(\" \")\n",
    "          text = text[-3:]\n",
    "          print(text)\n",
    "         \n",
    "          Predict_Next_Words(model, tokenizer, text)\n",
    "           \n",
    "      except Exception as e:\n",
    "        print(\"Error occurred: \",e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4821e592",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
